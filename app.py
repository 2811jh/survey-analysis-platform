import streamlit as st
import pandas as pd
import numpy as np
import os
import io
from datetime import datetime
import time

# å®‰å…¨å¯¼å…¥åˆ†ææ¨¡å—
try:
    from cross_analysis import process_crosstab
    CROSS_ANALYSIS_AVAILABLE = True
except ImportError:
    CROSS_ANALYSIS_AVAILABLE = False
    st.error("äº¤å‰åˆ†ææ¨¡å—åŠ è½½å¤±è´¥")

try:
    from text_analysis import (
        clean_text, manual_tagging, generate_wordcloud, 
        text_clustering, export_results
    )
    TEXT_ANALYSIS_AVAILABLE = True
except ImportError:
    TEXT_ANALYSIS_AVAILABLE = False
    st.error("æ–‡æœ¬åˆ†ææ¨¡å—åŠ è½½å¤±è´¥")

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="é—®å·æ•°æ®åˆ†æå¹³å°",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    /* ä¸»é¢˜è‰²é…ç½® */
    :root {
        --primary-color: #1E88E5;
        --secondary-color: #43A047;
        --accent-color: #FB8C00;
        --background-color: #F5F7FA;
    }
    
    /* ä¼˜åŒ–æ•´ä½“å¸ƒå±€ */
    .main {
        padding: 2rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        background-attachment: fixed;
    }
    
    /* ç¾åŒ–æ ‡é¢˜ */
    h1 {
        background: linear-gradient(120deg, #1E88E5, #43A047);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-weight: 800;
        font-size: 3rem !important;
        text-align: center;
        padding: 1rem 0;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    
    /* ç¾åŒ–å¡ç‰‡å®¹å™¨ */
    .stExpander {
        background: white;
        border-radius: 15px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        border: 1px solid rgba(255, 255, 255, 0.9);
        margin: 1rem 0;
    }
    
    /* ç¾åŒ–æŒ‰é’® */
    .stButton > button {
        background: linear-gradient(135deg, #1E88E5, #43A047);
        color: white;
        border: none;
        border-radius: 25px;
        padding: 0.75rem 2rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(30, 136, 229, 0.4);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(30, 136, 229, 0.6);
    }
    
    /* ç¾åŒ–ä¾§è¾¹æ  */
    .css-1d391kg {
        background: linear-gradient(180deg, #1E88E5 0%, #43A047 100%);
    }
    
    section[data-testid="stSidebar"] {
        background: linear-gradient(180deg, #ffffff 0%, #f0f2f6 100%);
        border-right: 2px solid #e0e0e0;
    }
    
    /* ç¾åŒ–æ–‡ä»¶ä¸Šä¼ å™¨ */
    .stFileUploader {
        background: white;
        border-radius: 10px;
        padding: 1rem;
        border: 2px dashed #1E88E5;
        transition: all 0.3s ease;
    }
    
    .stFileUploader:hover {
        border-color: #43A047;
        background: #f0f9ff;
    }
    
    /* ç¾åŒ–é€‰æ‹©æ¡† */
    .stSelectbox > div > div {
        background: white;
        border-radius: 10px;
        border: 2px solid #e0e0e0;
    }
    
    /* ç¾åŒ–å¤šé€‰æ¡† */
    .stMultiSelect > div > div {
        background: white;
        border-radius: 10px;
        border: 2px solid #e0e0e0;
    }
    
    /* ä¼˜åŒ–è¡¨æ ¼æ ·å¼ */
    .dataframe {
        border-radius: 10px;
        overflow: hidden;
    }
    
    /* ç¾åŒ–æŒ‡æ ‡å¡ç‰‡ */
    [data-testid="metric-container"] {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #1E88E5;
    }
    
    /* æ·»åŠ åŠ è½½åŠ¨ç”» */
    .stSpinner > div {
        border-color: #1E88E5 !important;
    }
    
    /* ç¾åŒ–æˆåŠŸæ¶ˆæ¯ */
    .stSuccess {
        background: linear-gradient(135deg, #43A047, #66BB6A);
        color: white;
        border-radius: 10px;
        padding: 1rem;
        font-weight: 600;
    }
    
    /* ç¾åŒ–é”™è¯¯æ¶ˆæ¯ */
    .stError {
        background: linear-gradient(135deg, #EF5350, #E53935);
        color: white;
        border-radius: 10px;
        padding: 1rem;
        font-weight: 600;
    }
    
    /* åŠ¨ç”»æ•ˆæœ */
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(20px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    .element-container {
        animation: fadeIn 0.5s ease-out;
    }
</style>
""", unsafe_allow_html=True)

# ä¼˜åŒ–çš„æ ‡é¢˜å’Œè¯´æ˜
st.markdown("""
<div style="background: white; border-radius: 20px; padding: 2rem; margin: -2rem -2rem 2rem -2rem; box-shadow: 0 10px 30px rgba(0,0,0,0.1);">
    <h1 style="margin: 0;">ğŸ“Š é—®å·æ•°æ®åˆ†æå¹³å°</h1>
    <p style="text-align: center; color: #666; font-size: 1.2rem; margin-top: 1rem;">
        ä¸“ä¸šçš„é—®å·æ•°æ®å¤„ç†ä¸åˆ†æå·¥å…·
    </p>
</div>
""", unsafe_allow_html=True)

# åŠŸèƒ½ä»‹ç»å¡ç‰‡
col1, col2 = st.columns(2)
with col1:
    st.markdown("""
    <div style="background: linear-gradient(135deg, #1E88E5, #42A5F5); color: white; padding: 1.5rem; border-radius: 15px; height: 150px;">
        <h3>ğŸ“ˆ äº¤å‰åˆ†æ</h3>
        <p>â€¢ æ”¯æŒå•é€‰é¢˜å’Œå¤šé€‰é¢˜äº¤å‰ç»Ÿè®¡<br>
        â€¢ è‡ªåŠ¨è®¡ç®—æ˜¾è‘—æ€§æ£€éªŒ<br>
        â€¢ ç”Ÿæˆä¸“ä¸šçš„ExcelæŠ¥å‘Š</p>
    </div>
    """, unsafe_allow_html=True)

with col2:
    st.markdown("""
    <div style="background: linear-gradient(135deg, #43A047, #66BB6A); color: white; padding: 1.5rem; border-radius: 15px; height: 150px;">
        <h3>ğŸ“ æ–‡æœ¬åˆ†æ</h3>
        <p>â€¢ æ™ºèƒ½æ–‡æœ¬æŒ–æ˜å’Œåˆ†ç±»<br>
        â€¢ ç”Ÿæˆç¾è§‚çš„è¯äº‘å›¾<br>
        â€¢ è‡ªåŠ¨èšç±»åˆ†æ</p>
    </div>
    """, unsafe_allow_html=True)

st.markdown("<br>", unsafe_allow_html=True)

# æ€§èƒ½ä¼˜åŒ–ï¼šç¼“å­˜æ•°æ®è¯»å–å‡½æ•°
@st.cache_data(show_spinner=False)
def load_data(file, file_type):
    """ç¼“å­˜æ–‡ä»¶è¯»å–ï¼Œé¿å…é‡å¤åŠ è½½"""
    if file_type == 'csv':
        try:
            return pd.read_csv(file, encoding='utf-8')
        except UnicodeDecodeError:
            try:
                return pd.read_csv(file, encoding='gbk')
            except UnicodeDecodeError:
                return pd.read_csv(file, encoding='latin-1')
    else:
        return pd.read_excel(file)

# æ€§èƒ½ä¼˜åŒ–ï¼šç¼“å­˜äº¤å‰åˆ†æç»“æœ
@st.cache_data(show_spinner=False)
def cached_crosstab(df_hash, row_questions, col_questions, sig_level, percent_format, data_column_width):
    """ç¼“å­˜äº¤å‰åˆ†æç»“æœ"""
    temp_input = f"temp_input_{df_hash}.xlsx"
    temp_output = f"temp_output_{df_hash}.xlsx"
    
    # è¿™é‡Œéœ€è¦é‡æ–°åˆ›å»ºDataFrameï¼Œå› ä¸ºcacheä¸èƒ½ç›´æ¥å­˜å‚¨DataFrame
    # å®é™…ä½¿ç”¨æ—¶ä¼šä»ç¼“å­˜çš„æ•°æ®é‡æ–°åˆ›å»º
    return None, None  # å ä½ç¬¦ï¼Œå®é™…å®ç°åœ¨ä¸‹é¢

# ä¾§è¾¹æ é€‰æ‹©åŠŸèƒ½
st.sidebar.markdown("""
<div style="background: linear-gradient(135deg, #1E88E5, #43A047); color: white; padding: 1rem; border-radius: 10px; margin-bottom: 1rem;">
    <h3 style="margin: 0; text-align: center;">âš™ï¸ æ§åˆ¶é¢æ¿</h3>
</div>
""", unsafe_allow_html=True)

analysis_type = st.sidebar.selectbox(
    "é€‰æ‹©åˆ†æç±»å‹",
    ["äº¤å‰åˆ†æ", "æ–‡æœ¬åˆ†æ"]
)

# æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.sidebar.file_uploader(
    "ä¸Šä¼ æ•°æ®æ–‡ä»¶",
    type=['xlsx', 'xls', 'csv'],
    help="æ”¯æŒExcelæ–‡ä»¶(.xlsx, .xls)å’ŒCSVæ–‡ä»¶(.csv)"
)

if uploaded_file is not None:
    # æ ¹æ®æ–‡ä»¶ç±»å‹è¯»å–æ•°æ®ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
    try:
        file_extension = uploaded_file.name.split('.')[-1].lower()
        
        # æ˜¾ç¤ºåŠ è½½åŠ¨ç”»
        with st.spinner('ğŸ”„ æ­£åœ¨åŠ è½½æ•°æ®...'):
            df = load_data(uploaded_file, file_extension)
            time.sleep(0.5)  # ç»™ç”¨æˆ·ä¸€ä¸ªè§†è§‰åé¦ˆ
        
        # æˆåŠŸæç¤ºå¸¦åŠ¨ç”»
        success_placeholder = st.sidebar.empty()
        success_placeholder.success(f"âœ… æ–‡ä»¶åŠ è½½æˆåŠŸï¼å…± {len(df)} æ¡æ•°æ®ï¼Œ{len(df.columns)} ä¸ªå­—æ®µ")
        
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        with st.sidebar.expander("ğŸ“Š æ–‡ä»¶ä¿¡æ¯"):
            st.write(f"**æ–‡ä»¶å:** {uploaded_file.name}")
            st.write(f"**æ–‡ä»¶ç±»å‹:** {file_extension.upper()}")
            st.write(f"**æ•°æ®è¡Œæ•°:** {len(df)}")
            st.write(f"**å­—æ®µæ•°é‡:** {len(df.columns)}")
            
    except Exception as e:
        st.sidebar.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
        st.stop()
    
    # æ˜¾ç¤ºåˆ—åä¾›é€‰æ‹©
    columns = df.columns.tolist()
    
    # æ·»åŠ æ•°æ®é¢„è§ˆåŠŸèƒ½
    with st.expander("ğŸ” æ•°æ®é¢„è§ˆ", expanded=False):
        st.subheader("å‰5è¡Œæ•°æ®")
        st.dataframe(df.head(), use_container_width=True)
        
        st.subheader("æ•°æ®æ¦‚è§ˆ")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ€»è¡Œæ•°", len(df))
        with col2:
            st.metric("æ€»åˆ—æ•°", len(df.columns))
        with col3:
            st.metric("ç¼ºå¤±å€¼", df.isnull().sum().sum())
        
        # æ˜¾ç¤ºå­—æ®µåˆ—è¡¨
        st.subheader("å­—æ®µåˆ—è¡¨")
        for i, col in enumerate(df.columns, 1):
            st.write(f"{i}. **{col}** (ç±»å‹: {df[col].dtype})")
    
    if analysis_type == "äº¤å‰åˆ†æ":
        st.header("ğŸ“ˆ äº¤å‰åˆ†æ")
        
        if not CROSS_ANALYSIS_AVAILABLE:
            st.error("äº¤å‰åˆ†æåŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•")
            st.stop()
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("è¡Œå˜é‡é…ç½®")
            row_questions = st.multiselect(
                "é€‰æ‹©è¡Œå˜é‡ï¼ˆæ”¯æŒå¤šé€‰ï¼‰",
                columns,
                help="é€‰æ‹©è¦ä½œä¸ºè¡Œç»´åº¦çš„é—®é¢˜"
            )
        
        with col2:
            st.subheader("åˆ—å˜é‡é…ç½®")
            col_questions = st.multiselect(
                "é€‰æ‹©åˆ—å˜é‡ï¼ˆæ”¯æŒå¤šé€‰ï¼‰",
                columns,
                help="é€‰æ‹©è¦ä½œä¸ºåˆ—ç»´åº¦çš„é—®é¢˜"
            )
        
        # é«˜çº§é€‰é¡¹
        with st.expander("é«˜çº§é€‰é¡¹"):
            col1, col2, col3 = st.columns(3)
            with col1:
                sig_level = st.selectbox(
                    "æ˜¾è‘—æ€§æ°´å¹³",
                    [0.05, 0.01, 0.001],
                    index=0
                )
            with col2:
                percent_format = st.text_input(
                    "ç™¾åˆ†æ¯”æ ¼å¼",
                    value="0.00%"
                )
            with col3:
                data_column_width = st.number_input(
                    "æ•°æ®åˆ—å®½åº¦",
                    min_value=10,
                    max_value=50,
                    value=20
                )
        
        # æ‰§è¡Œåˆ†æï¼ˆå¸¦ç¾åŒ–æŒ‰é’®ï¼‰
        if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True):
            if row_questions and col_questions:
                # åˆ›å»ºè¿›åº¦æ¡
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                try:
                    # åˆ†æ­¥æ‰§è¡Œï¼Œæ˜¾ç¤ºè¿›åº¦
                    status_text.text("ğŸ“Š æ­£åœ¨å‡†å¤‡æ•°æ®...")
                    progress_bar.progress(20)
                    time.sleep(0.5)
                    
                    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                    temp_input = "temp_input.xlsx"
                    temp_output = "temp_output.xlsx"
                    df.to_excel(temp_input, index=False)
                    
                    status_text.text("âš™ï¸ æ­£åœ¨æ‰§è¡Œäº¤å‰åˆ†æ...")
                    progress_bar.progress(60)
                    
                    # æ‰§è¡Œåˆ†æ
                    crosstab_df, sig_df = process_crosstab(
                        input_file=temp_input,
                        output_file=temp_output,
                        row_questions=row_questions,
                        col_questions=col_questions,
                        sig_levels=[sig_level],
                        percent_format=percent_format,
                        data_column_width=data_column_width
                    )
                    
                    status_text.text("ğŸ“ˆ æ­£åœ¨ç”Ÿæˆç»“æœ...")
                    progress_bar.progress(90)
                    time.sleep(0.5)
                    
                    # å®Œæˆè¿›åº¦æ¡
                    status_text.text("âœ… åˆ†æå®Œæˆï¼")
                    progress_bar.progress(100)
                    time.sleep(1)
                    
                    # æ¸…é™¤è¿›åº¦æ¡
                    progress_bar.empty()
                    status_text.empty()
                    
                    # æˆåŠŸæ¶ˆæ¯
                    st.balloons()  # æ·»åŠ åº†ç¥åŠ¨ç”»
                    st.success("ğŸ‰ äº¤å‰åˆ†æå®Œæˆï¼")
                    
                    # æ˜¾ç¤ºç»“æœ
                    st.subheader("ğŸ“Š äº¤å‰ç»Ÿè®¡ç»“æœ")
                    with st.container():
                        st.dataframe(crosstab_df.head(50), use_container_width=True)
                    
                    # ä¸‹è½½æŒ‰é’®ï¼ˆç¾åŒ–ï¼‰
                    with open(temp_output, 'rb') as f:
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½å®Œæ•´ç»“æœ",
                            data=f.read(),
                            file_name=f"äº¤å‰åˆ†æç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True
                        )
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    os.remove(temp_input)
                    os.remove(temp_output)
                        
                except Exception as e:
                    st.error(f"âŒ åˆ†æå‡ºé”™: {str(e)}")
            else:
                st.warning("è¯·é€‰æ‹©è¡Œå˜é‡å’Œåˆ—å˜é‡")
    
    elif analysis_type == "æ–‡æœ¬åˆ†æ":
        st.header("ğŸ“ æ–‡æœ¬åˆ†æ")
        
        if not TEXT_ANALYSIS_AVAILABLE:
            st.error("æ–‡æœ¬åˆ†æåŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•")
            st.stop()
        
        # é€‰æ‹©æ–‡æœ¬åˆ—
        text_column = st.selectbox(
            "é€‰æ‹©æ–‡æœ¬åˆ—",
            columns,
            help="é€‰æ‹©åŒ…å«æ–‡æœ¬å†…å®¹çš„åˆ—"
        )
        
        # å…¶ä»–å˜é‡
        other_vars = st.multiselect(
            "é€‰æ‹©å…¶ä»–å˜é‡ï¼ˆå¯é€‰ï¼‰",
            [col for col in columns if col != text_column],
            help="é€‰æ‹©è¦ä¿ç•™çš„å…¶ä»–åˆ—"
        )
        
        # åœç”¨è¯é…ç½®
        with st.expander("åœç”¨è¯é…ç½®"):
            default_stopwords = ["çš„", "äº†", "æ˜¯", "æœ‰äº›", "å› ä¸º", "æ¸¸æˆ", "ä¸–ç•Œ", 
                               "è€Œä¸”", "éå¸¸", "å»ºè®®", "å¸Œæœ›", "ä»€ä¹ˆ", "ä¸è¦"]
            stopwords_text = st.text_area(
                "åœç”¨è¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                value="\n".join(default_stopwords),
                height=200
            )
            stopwords = stopwords_text.split("\n")
        
        # æ ‡ç­¾é…ç½®
        with st.expander("æ ‡ç­¾å…³é”®è¯é…ç½®"):
            st.markdown("é…ç½®æ ‡ç­¾å’Œå¯¹åº”çš„å…³é”®è¯ï¼Œç”¨äºæ–‡æœ¬åˆ†ç±»")
            
            # é»˜è®¤æ ‡ç­¾é…ç½®
            default_tags = {
                "æ ¸å¿ƒç©æ³•": ["å¥½ç©", "ç”Ÿå­˜", "åˆ›é€ ", "çº¢çŸ³", "æŒ‡ä»¤"],
                "ç¤¾äº¤è”æœº": ["è”æœº", "å¥½å‹", "æœåŠ¡å™¨", "å¤šäººæ¸¸æˆ"],
                "æ€§èƒ½ä½“éªŒ": ["å¡é¡¿", "é—ªé€€", "åŠ è½½æ…¢", "æ‰å¸§"],
                "ç‰ˆæœ¬ç‰¹æ€§": ["æ›´æ–°", "ç‰ˆæœ¬", "1.20", "æ–°åŠŸèƒ½"],
                "æ¨¡ç»„ç»„ä»¶": ["æ¨¡ç»„", "MOD", "mod", "å…‰å½±", "æè´¨åŒ…"]
            }
            
            # åŠ¨æ€æ·»åŠ æ ‡ç­¾
            tag_keywords = {}
            for tag, keywords in default_tags.items():
                keywords_str = st.text_input(
                    f"{tag} å…³é”®è¯ï¼ˆé€—å·åˆ†éš”ï¼‰",
                    value=", ".join(keywords)
                )
                if keywords_str:
                    tag_keywords[tag] = [k.strip() for k in keywords_str.split(",")]
        
        # èšç±»å‚æ•°
        col1, col2 = st.columns(2)
        with col1:
            n_clusters = st.slider(
                "èšç±»æ•°é‡",
                min_value=3,
                max_value=20,
                value=10
            )
        with col2:
            max_samples = st.slider(
                "æ¯ç±»æ˜¾ç¤ºæ ·æœ¬æ•°",
                min_value=5,
                max_value=50,
                value=20
            )
        
        # æ‰§è¡Œåˆ†æ
        if st.button("ğŸš€ å¼€å§‹æ–‡æœ¬åˆ†æ", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨æ‰§è¡Œæ–‡æœ¬åˆ†æ..."):
                try:
                    # æ•°æ®å‡†å¤‡
                    text_df = df[[text_column] + other_vars].copy()
                    
                    # æ–‡æœ¬æ¸…æ´—
                    invalid_words = ['æ— ', ' ', 'æ²¡æœ‰', 'ä¸çŸ¥é“']
                    clean_df = clean_text(text_df, text_column, invalid_words)
                    
                    st.info(f"æ¸…æ´—åæ•°æ®é‡: {len(clean_df)} æ¡")
                    
                    # æ ‡ç­¾åŒ¹é…
                    if tag_keywords:
                        clean_df[["åŒ¹é…æ ‡ç­¾", "åŒ¹é…å…³é”®è¯"]] = clean_df[text_column].apply(
                            lambda x: pd.Series(manual_tagging(x, tag_keywords))
                        )
                    
                    # ç”Ÿæˆè¯äº‘
                    st.subheader("è¯äº‘å›¾")
                    wordcloud_path = "temp_wordcloud.png"
                    generate_wordcloud(
                        texts=clean_df[text_column],
                        stopwords=stopwords,
                        save_path=wordcloud_path
                    )
                    
                    # æ˜¾ç¤ºè¯äº‘
                    if os.path.exists(wordcloud_path):
                        st.image(wordcloud_path, caption="è¯äº‘åˆ†æç»“æœ")
                        
                        # æä¾›è¯äº‘ä¸‹è½½
                        with open(wordcloud_path, "rb") as f:
                            st.download_button(
                                label="ğŸ“¥ ä¸‹è½½è¯äº‘å›¾",
                                data=f.read(),
                                file_name=f"è¯äº‘å›¾_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
                                mime="image/png"
                            )
                        os.remove(wordcloud_path)
                    
                    # æ–‡æœ¬èšç±»
                    st.subheader("æ–‡æœ¬èšç±»ç»“æœ")
                    cluster_df, cluster_labels = text_clustering(
                        clean_df[text_column],
                        n_clusters=n_clusters,
                        max_samples=max_samples
                    )
                    clean_df["èšç±»æ ‡ç­¾"] = cluster_labels
                    
                    # æ˜¾ç¤ºèšç±»ç»Ÿè®¡
                    st.dataframe(cluster_df)
                    
                    # å¯¼å‡ºç»“æœ
                    output_path = "temp_text_analysis.xlsx"
                    export_results(clean_df, cluster_df, output_path)
                    
                    # ä¸‹è½½æŒ‰é’®
                    with open(output_path, 'rb') as f:
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½åˆ†æç»“æœ",
                            data=f.read(),
                            file_name=f"æ–‡æœ¬åˆ†æç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    os.remove(output_path)
                    
                    st.success("æ–‡æœ¬åˆ†æå®Œæˆï¼")
                    
                except Exception as e:
                    st.error(f"åˆ†æå‡ºé”™: {str(e)}")
                    
else:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¸Šä¼ Excelæ–‡ä»¶å¼€å§‹åˆ†æ")

# é¡µè„š
st.markdown("---")
st.markdown("ğŸ“Š é—®å·æ•°æ®åˆ†æå¹³å° v1.0 | æ”¯æŒäº¤å‰åˆ†æå’Œæ–‡æœ¬æŒ–æ˜")